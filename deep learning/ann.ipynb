{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the data set taken from a bank which collected some information from the bank , and a deciding factor that custumer has left the bank or not\n",
    "@ bank observed that their custumers aur leaving the bank  so we have to se the corelation that weather the custumer will stay in bank aur not  \n",
    "@ this is to prevent the custumers to leave the bank by giving that custumer offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING THE LIBRARIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =pd.read_csv(r\"C:\\Users\\RIYAN SINGH\\Desktop\\course\\Machine Learning A-Z (Codes and Datasets)\\Part 8 - Deep Learning\\Section 39 - Artificial Neural Networks (ANN)\\Python\\Churn_Modelling.csv\")\n",
    "x=dataset.iloc[:,3:-1].values\n",
    "y=dataset.iloc[:,-1].values# here we are having key values( which ARE NOT USEFUL) of the custumer in first 3 columns so we exclude them for ann easie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING THE CATAGORICAL DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we are using the lable encoder for encoding the male and female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "x[:,2]=le.fit_transform(x[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 0, ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 0, ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 0, ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 1, ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# appling one hut coding to the geographical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct= ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[1])],remainder='passthrough' )\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting the data into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featur escaling \n",
    "feature scaling is so important to the deep learning that we feature scale whole data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99850112  1.71490137 -0.57273139 ... -1.55337352  0.97725852\n",
      "   0.42739449]\n",
      " [ 1.00150113 -0.58312392 -0.57273139 ... -1.55337352 -1.02327069\n",
      "  -1.02548708]\n",
      " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n",
      "  -0.94479772]\n",
      " ...\n",
      " [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n",
      "  -0.14096853]\n",
      " [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n",
      "   0.01781218]\n",
      " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017 -1.02327069\n",
      "  -1.15822478]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.fit_transform(x_test)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALLING THE ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann= tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add 1st hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding the 2nd hidden layes.\n",
    "here we can change the hyper parameter to make output more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add the output layer ,in output layer you have the output neurons as per the output class\n",
    "as we only have binary class so we have 1 neuron here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))# when the class increases then we use softmax activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to give 3 parameters while training the ann ( OPTIMIZER, LOSS_FUNCTION,MATRIX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE DATASET ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8634\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8634\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8633\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8618\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8633\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8641\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8631\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8645\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8634\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8627\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8637\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8622\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8622\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8619\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8641\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8625\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8625\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8635\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8622\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8639\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8627\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8635\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8659\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8630\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8631\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8631\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8624\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8627\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8629\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8631\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8634\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8641\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8626\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8634\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8637\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8626\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8616\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8643\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8629\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8611\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8622\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8616\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8624\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8635\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8619\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8637\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8630\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8630\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8620\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x268e5e075b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train,batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pridecting the single value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here input of predicted value must b in 2d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same scaling must b there ,so to make it of same scale we have used transform method from standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING THE TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 791us/step\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1526   59]\n",
      " [ 208  207]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8665"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
